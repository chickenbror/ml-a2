{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13c4629",
   "metadata": {},
   "source": [
    "### LT2326 HT21 Assignment 2 \n",
    "##### Calvin Kullvén Liao\n",
    "\n",
    "##### ( The notebook and 3 trained models are also accessible on https://github.com/chickenbror/ml-a2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e157e7e",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "I made changes to the read_data and convert_to_index functions from the demo, so that the train/test datasets are represented as tuples of (x,y) (so that they can be batch-loaded using DataLoaader), with paddings and start/end tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8746f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27560932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chinese_data(inputfilename):\n",
    "    '''\n",
    "    Reads the input file, returns a list of [(x,y)...], \n",
    "    where x = a Chinese sentence string, y = a binary list [1,0...],\n",
    "    indicating whether a character is the first of a Chinese word.\n",
    "    Eg, (\"這次遊行的特色\", [1, 1, 1, 0, 1, 1, 0,]) for 這/次/遊行/的/特色\n",
    "    '''\n",
    "    with open(inputfilename, \"r\") as inputfile:\n",
    "        xy_list, collection_words, collection_labels = [], [], []\n",
    "        for line in inputfile:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            columns = line.split()\n",
    "            if columns == []: # When reading a blank line\n",
    "                xy_list.append((''.join(collection_words), collection_labels)) # append the (x,y)\n",
    "                collection_words, collection_labels = [], [] # Reset the x,y lists\n",
    "                continue\n",
    "            collection_words.append(columns[1])\n",
    "            collection_labels += [1] + ([0] * (len(columns[1]) - 1)) # 1 for first char, 0 for the rest\n",
    "    return xy_list\n",
    "\n",
    "def get_chars_and_ids(sentences, extra_chars=['<PAD>','<START>','<END>']):\n",
    "    '''\n",
    "    Arg:\n",
    "        sentences: a list of sentence-strings\n",
    "    Returns:\n",
    "        list of the character set, plus extras (default: pad, start & end tags), \n",
    "        dict of {character:char_id}, tag-and-id by default <PAD>:0, <START>:1, <END>:2\n",
    "    '''\n",
    "    char_set = set((char for sen in sentences for char in sen))\n",
    "    char_list = extra_chars + list(char_set)\n",
    "    ids_dict = {char:i for i,char in enumerate(char_list)}\n",
    "    return char_list, ids_dict\n",
    "\n",
    "def sentence_to_ids(sentence, ids_dict, add_tags=True, padding_len=512): \n",
    "    '''Turns a sentence-string into a [ids] array, adds start/end tag by default'''\n",
    "    \n",
    "    ids = np.array([ids_dict[char] for char in sentence]) # string to ids\n",
    "    \n",
    "    if add_tags and ('<START>' in ids_dict) and ('<END>' in ids_dict):\n",
    "        start_id, end_id = ids_dict['<START>'], ids_dict['<END>']\n",
    "        ids = np.pad(ids, (1, 1), 'constant', constant_values=(start_id, end_id)) # pad with start/end tags\n",
    "    \n",
    "    pad_id = ids_dict['<PAD>'] if '<PAD>' in ids_dict else len(ids_dict)+1 # pad_id or vocabsize+1\n",
    "    paddings = np.repeat(pad_id, padding_len - len(ids)+1) # Make sure even the longest sen has one padding\n",
    "    ids = np.concatenate((ids, paddings))\n",
    "    return ids\n",
    "\n",
    "def convert_and_pad(raw_xy_data, ids_dict, y_pad_id=-1):\n",
    "    '''Turns a list of (sentence, labels) to (padded_sentence_ids, padded_labels)'''\n",
    "    \n",
    "    max_len = max((len(x) for x,y in raw_xy_data))+2 # num_chars + 2 tags\n",
    "    id_and_pad = lambda x : sentence_to_ids(x, ids_dict=ids_dict, padding_len=max_len)\n",
    "    add_tag_and_pad_y = lambda y : np.concatenate( \n",
    "                                        (np.pad(y, 1, 'constant', constant_values=1), # label <start>/<end> as 1\n",
    "                                         np.repeat(y_pad_id, max_len-len(y)-1) # pads: max_len - len(y)- 2 tags +1\n",
    "                                        ))\n",
    "    \n",
    "    ided_and_padded = ((id_and_pad(x), np.array(len(x)+2), add_tag_and_pad_y(y)) for x,y in raw_xy_data)\n",
    "    return list(ided_and_padded) # (tagged_and_padded_x, len_x_plus_two_tags, padded_y_plus_two_more_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e570ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xy_raw = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu')\n",
    "test_xy_raw = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74625d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>其便當都是買來的，就算加熱也是由媽媽負責（後來揭曉其實是避免帶來厄運），父親則在電視台上班。</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>這次遊行最大的特色，在於越來越多年輕人上街遊行，而且當中不乏行動激烈的躁少年。</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>懷孕期為421至457日。</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>婷婷向昏迷中的婆婆訴說，為什麼生活會與她想像的不一樣。</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究...   \n",
       "1     其便當都是買來的，就算加熱也是由媽媽負責（後來揭曉其實是避免帶來厄運），父親則在電視台上班。   \n",
       "2            這次遊行最大的特色，在於越來越多年輕人上街遊行，而且當中不乏行動激烈的躁少年。   \n",
       "3                                      懷孕期為421至457日。   \n",
       "4                        婷婷向昏迷中的婆婆訴說，為什麼生活會與她想像的不一樣。   \n",
       "\n",
       "                                                   y  \n",
       "0  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...  \n",
       "1  [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, ...  \n",
       "2  [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, ...  \n",
       "3            [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]  \n",
       "4  [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_xy_raw, columns=['x','y'])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d940ad3",
   "metadata": {},
   "source": [
    "#### Sandwich x/y between start/end tags and pad to 185 chars long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3e1cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x_len</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1289, 1477, 1724, 3511, 128, 2476, 1233, 8...</td>\n",
       "      <td>60</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1640, 2879, 919, 3021, 1233, 329, 625, 249...</td>\n",
       "      <td>48</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1349, 2371, 3034, 1605, 2805, 835, 2495, 8...</td>\n",
       "      <td>41</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 584, 643, 1515, 553, 1703, 567, 66, 37, 17...</td>\n",
       "      <td>15</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2292, 2292, 920, 2793, 75, 1953, 2495, 356...</td>\n",
       "      <td>29</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x x_len  \\\n",
       "0  [1, 1289, 1477, 1724, 3511, 128, 2476, 1233, 8...    60   \n",
       "1  [1, 1640, 2879, 919, 3021, 1233, 329, 625, 249...    48   \n",
       "2  [1, 1349, 2371, 3034, 1605, 2805, 835, 2495, 8...    41   \n",
       "3  [1, 584, 643, 1515, 553, 1703, 567, 66, 37, 17...    15   \n",
       "4  [1, 2292, 2292, 920, 2793, 75, 1953, 2495, 356...    29   \n",
       "\n",
       "                                                   y  \n",
       "0  [1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...  \n",
       "1  [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, ...  \n",
       "2  [1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, ...  \n",
       "3  [1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "4  [1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of all chars and their ids\n",
    "chars_list, ids_dict = get_chars_and_ids((x for x,y in train_xy_raw + test_xy_raw)) \n",
    "\n",
    "# Convert (sentence,labels) to (padded ids, len_padded_ids, padded labels)\n",
    "train_xy = convert_and_pad(train_xy_raw, ids_dict)\n",
    "test_xy = convert_and_pad(test_xy_raw, ids_dict)\n",
    "\n",
    "pd.DataFrame(train_xy, columns=['x','x_len','y'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "07a7e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Segmenter(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0) # padding id = 0\n",
    "        self.lstm = nn.LSTM(self.emb_size, 150, batch_first=True) # in_size, hidden_size, layers=1\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.lin = nn.Linear(150, 2)\n",
    "        self.softmax = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        embs = self.emb(x) # B,185,200\n",
    "        \n",
    "        # pack=>lstm=>unpack\n",
    "        packed = pack_padded_sequence(embs, x_len.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        rnn_output, (_,_) = self.lstm(packed) # B, 185, 150\n",
    "        unpacked, _ = pad_packed_sequence(rnn_output, batch_first=True)\n",
    "        \n",
    "        # sigmoid=>linear 2=>softmax\n",
    "        output = self.sig1(unpacked) # B, 185, 150\n",
    "        output = self.lin(output) # B, 185, 150\n",
    "        output = self.softmax(output) # B, 185, 2\n",
    "        output = output[:, :max(x_len), :] # outshape B, max_x_len_of_batch(<=184), 2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6356763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "96dd71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_xy, epochs, device, model, model_fn, batch_size=50, lr=0.005):\n",
    "    \n",
    "    m = model.to(device)\n",
    "    m.train()\n",
    "    \n",
    "    batching = DataLoader(train_xy, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss_fn = nn.NLLLoss(ignore_index=-1) # ignore y padding\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (x, x_len, y) in enumerate(batching):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            out = m(x, x_len) # B, max_x_len, 2 => permute to B,2,max_x_len\n",
    "            expect = y[:, :max(x_len)] # B, max_x_len\n",
    "            \n",
    "            loss = loss_fn(out.permute(0,2,1), expect) \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {e+1} avg loss {total_loss/(i+1)}\", end='\\r')\n",
    "        print()\n",
    "        torch.save(m, model_fn)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2086c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg loss 0.40239770635962485\n",
      "Epoch 2 avg loss 0.21714450158178805\n",
      "Epoch 3 avg loss 0.16131862122565507\n",
      "Epoch 4 avg loss 0.12739679208025337\n",
      "Epoch 5 avg loss 0.10103010442107915\n",
      "Epoch 6 avg loss 0.08010265226475895\n",
      "Epoch 7 avg loss 0.063747962843626744\n",
      "Epoch 8 avg loss 0.052345541305840015\n",
      "Epoch 9 avg loss 0.042464165366254755\n",
      "Epoch 10 avg loss 0.036720286798663446\n",
      "Epoch 11 avg loss 0.034124823776073756\n",
      "Epoch 12 avg loss 0.031660708738490944\n",
      "Epoch 13 avg loss 0.024191916862037033\n",
      "Epoch 14 avg loss 0.018214076897129415\n",
      "Epoch 15 avg loss 0.013349636929342523\n",
      "Epoch 16 avg loss 0.010331295733340084\n",
      "Epoch 17 avg loss 0.0071708931151079025\n",
      "Epoch 18 avg loss 0.0054092381964437665\n",
      "Epoch 19 avg loss 0.0039224000211106615\n",
      "Epoch 20 avg loss 0.0028487879317253836\n",
      "Epoch 21 avg loss 0.0022939097907510586\n",
      "Epoch 22 avg loss 0.0019211746766814034\n",
      "Epoch 23 avg loss 0.0018902905605500564\n",
      "Epoch 24 avg loss 0.0017987071027164348\n",
      "Epoch 25 avg loss 0.0017561757726070938\n",
      "Epoch 26 avg loss 0.0015363907965365796\n",
      "Epoch 27 avg loss 0.0013053843511443126\n",
      "Epoch 28 avg loss 0.0012429764603439253\n",
      "Epoch 29 avg loss 0.0017299260056461208\n",
      "Epoch 30 avg loss 0.0441781574350898145\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(ids_dict)\n",
    "model_A_init = Segmenter(vocab_size=vocab_size, emb_size=200)\n",
    "gpu = 'cuda:3'\n",
    "\n",
    "model_A = train_model(train_xy, epochs=30, device=gpu, model=model_A_init, model_fn='model_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88720216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (emb): Embedding(3650, 200, padding_idx=0)\n",
       "  (lstm): LSTM(200, 150, batch_first=True)\n",
       "  (sig1): Sigmoid()\n",
       "  (lin): Linear(in_features=150, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere (no need to give model(*args))\n",
    "model_A = torch.load('model_A').to('cpu')\n",
    "model_A.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bbfc6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_batching = DataLoader(test_xy, batch_size=10)\n",
    "    for i,(x,x_len,y) in enumerate(test_batching):\n",
    "        rawpredictions = model_A(x, x_len)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "67515cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " '然',\n",
       " '而',\n",
       " '，',\n",
       " '這',\n",
       " '樣',\n",
       " '的',\n",
       " '處',\n",
       " '理',\n",
       " '也',\n",
       " '衍',\n",
       " '生',\n",
       " '了',\n",
       " '一',\n",
       " '些',\n",
       " '問',\n",
       " '題',\n",
       " '。',\n",
       " '<END>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ [chars_list[i] for i in sen_ids] for sen_ids in x.detach().tolist()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "dd430a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawpredictions.argmax(2) [0]\n",
    "# torch.argmax(rawpredictions, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc66a89",
   "metadata": {},
   "source": [
    "### Part 1 - Sentence generation (15 points).\n",
    "Convert the model in Demo 2.1 into a character-based sentence generator. (Strip out the word segmentation objective.)  The model should, given a start symbol, produce a variety of sentences that terminate with a stop symbol (you will have to add these to the data).  The sentences that it generates should be of reasonable average length compared to the sentences in the training corpus (this needn't be precise). \n",
    "\n",
    "Report and discuss the changes you made to the notebook using Markdown inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ba8b07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size=200, lstm_size=150):\n",
    "        super(SentenceGenerator, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = 1\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.emb_size, padding_idx=0) #V=>200\n",
    "        \n",
    "        self.lstm = nn.LSTM( #200=>150\n",
    "            input_size=self.emb_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "#             dropout=0.2,\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.lstm_size, self.vocab_size) #150=>V\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        embed = self.embedding(x) #B,184,200\n",
    "        output, hidden_state = self.lstm(embed)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden_state\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.num_layers, batch_size, self.lstm_size).zero_(),\n",
    "                weight.new(self.num_layers, batch_size, self.lstm_size).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a05fc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_B(train_xy, model, epochs, device, model_fn, batch_size=50):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    batching = DataLoader(train_xy, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for i, (x,x_len,_) in enumerate(batching): # y not needed\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            hidden = tuple([s.data for s in hidden])\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # output preditions and update hidden state\n",
    "            predictions, hidden = model(x[:,:max(x_len)], hidden) # B,max_x_len => B,max_x_len,V\n",
    "            expect = x[:, 1:max(x_len)+1] # next words\n",
    "            \n",
    "            loss = criterion(predictions.transpose(1, 2), expect)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            print(f\"epoch {e+1} avg loss: {total_loss/(i+1)}\", end='\\r')\n",
    "\n",
    "        print()\n",
    "        torch.save(model, model_fn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "10810753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg loss: 6.8814031302928935\n",
      "epoch 2 avg loss: 6.1469741880893715\n",
      "epoch 3 avg loss: 5.8922610700130465\n",
      "epoch 4 avg loss: 5.6767599165439635\n",
      "epoch 5 avg loss: 5.4921111762523656\n",
      "epoch 6 avg loss: 5.3324235677719125\n",
      "epoch 7 avg loss: 5.1947582960128785\n",
      "epoch 8 avg loss: 5.0737626612186435\n",
      "epoch 9 avg loss: 4.9683668255805975\n",
      "epoch 10 avg loss: 4.8688516974449155\n",
      "epoch 11 avg loss: 4.7771672427654276\n",
      "epoch 12 avg loss: 4.6931721746921545\n",
      "epoch 13 avg loss: 4.6163374125957495\n",
      "epoch 14 avg loss: 4.5417279183864595\n",
      "epoch 15 avg loss: 4.4688791751861575\n",
      "epoch 16 avg loss: 4.4041201472282415\n",
      "epoch 17 avg loss: 4.3387535035610215\n",
      "epoch 18 avg loss: 4.2762805759906775\n",
      "epoch 19 avg loss: 4.2161924004554745\n",
      "epoch 20 avg loss: 4.1584902167320255\n",
      "epoch 21 avg loss: 4.1040454447269445\n",
      "epoch 22 avg loss: 4.0473456174135215\n",
      "epoch 23 avg loss: 3.9946828246116646\n",
      "epoch 24 avg loss: 3.9425329953432082\n",
      "epoch 25 avg loss: 3.8937939226627353\n",
      "epoch 26 avg loss: 3.8444074749946595\n",
      "epoch 27 avg loss: 3.7954241931438446\n",
      "epoch 28 avg loss: 3.7502996921539307\n",
      "epoch 29 avg loss: 3.7047264844179155\n",
      "epoch 30 avg loss: 3.6590995728969573\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(ids_dict)\n",
    "model_B_init = SentenceGenerator(vocab_size=vocab_size)\n",
    "gpu = 'cuda:0'\n",
    "\n",
    "model_B = train_model_B(train_xy, model=model_B_init, epochs=30, device=gpu, model_fn='model_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0ec07e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceGenerator(\n",
       "  (embedding): Embedding(3650, 200, padding_idx=0)\n",
       "  (lstm): LSTM(200, 150, batch_first=True)\n",
       "  (fc): Linear(in_features=150, out_features=3650, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = torch.load('model_B').to('cpu')\n",
    "model_B.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8f4c58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_sentence(ids_dict, chars_list, model, text, consider_prev=0):\n",
    "    model.eval()\n",
    "\n",
    "    chars = text\n",
    "    hidden = model.init_hidden(1) #batchsize=1\n",
    "\n",
    "    while True:\n",
    "        # (if consider_prev=0 or greater than the nr of chars, the whole sentence so far is considered)\n",
    "        current_ids = [ids_dict[c] for c in chars[-consider_prev:]] \n",
    "        \n",
    "        x = torch.tensor([current_ids]).long() # Consider <start> ~ last predicted char\n",
    "        with torch.no_grad():\n",
    "            y_pred, hidden = model(x, hidden)\n",
    "\n",
    "        last_char_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_char_logits, dim=0).detach().numpy()\n",
    "        sample_char_index = np.random.choice(len(last_char_logits), p=p)\n",
    "        next_char = chars_list[sample_char_index]\n",
    "#         if next_char == '<PAD>':\n",
    "#             continue\n",
    "        chars.append(next_char)\n",
    "        if next_char=='<END>':\n",
    "            break\n",
    "\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c365bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', '這', '超', '過', '車', '人', '霸', '於', '1', '9', '1', '9', '年', '所', '有', '開', '始', '才', '公', '司', '（', 'M', '2', '1', '街', '）', '。', '<END>']\n"
     ]
    }
   ],
   "source": [
    "print( generate_pred_sentence(ids_dict, chars_list, model=model_B, text=['<START>','這']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "afe3dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_sentences(consider_prev, n_sentences = 20, print_sentences=False):\n",
    "\n",
    "    current_len = 0\n",
    "    for i in range(n_sentences):\n",
    "        words = generate_pred_sentence(ids_dict, chars_list, model=model_B, text=['<START>'],\n",
    "                                      consider_prev=consider_prev)\n",
    "        \n",
    "        if print_sentences:\n",
    "            print(''.join(words), len(words))\n",
    "        current_len+=len(words)\n",
    "    print('Avg sentence length:', current_len/n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1916086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length in train set: 41.10357768326244\n"
     ]
    }
   ],
   "source": [
    "avg_sent_len = np.array([l for x,l,y in train_xy]).mean()\n",
    "print('Average sentence length in train set:', avg_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "42869134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consider the previous 0 characters:\tAvg sentence length: 43.45\n",
      "consider the previous 1 characters:\tAvg sentence length: 1537.9\n",
      "consider the previous 5 characters:\tAvg sentence length: 1075.9\n",
      "consider the previous 10 characters:\tAvg sentence length: 251.05\n",
      "consider the previous 20 characters:\tAvg sentence length: 46.95\n",
      "consider the previous 30 characters:\tAvg sentence length: 35.65\n",
      "consider the previous 60 characters:\tAvg sentence length: 36.95\n",
      "consider the previous 100 characters:\tAvg sentence length: 34.25\n",
      "consider the previous 150 characters:\tAvg sentence length: 32.4\n",
      "consider the previous 184 characters:\tAvg sentence length: 47.1\n"
     ]
    }
   ],
   "source": [
    "# Trying considering different previous nr of chars, and see the avg length of generated sentences\n",
    "for i in (0,1,5,10,20,30,60,100,150,184):\n",
    "    print(f'consider the previous {i} characters:', end='\\t')\n",
    "    generate_n_sentences(consider_prev=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "78aa56a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>明貝爾龍的常用之一在在當時戰爭，芝加原決onetihaw，她澳慶草加親及黎安城家那山大陸等的印度部，美國空入命令，帝國適合葬有醫動的法之意。<END> 72\n",
      "<START>但其性也涵到：成為明博基底起。<END> 17\n",
      "<START>為了什麼音水感強前的重要相對，亦開始由各民族模舉行，一句手段題在內部觀需求神的一個增有相想相關「考嘲升領」，以用禁止釋滅深栓，而陷養獎。<END> 70\n",
      "<START>中國教宗教育日最皇后措贊拒絕無能在名。<END> 21\n",
      "<START>以9個經併上，為該國家合票物是你對的陸體寫合作的評死。<END> 29\n",
      "<START>1890年美國人口普查國戰爭間。<END> 18\n",
      "<START>報，西藏想雙紅拖入震病，王度將阿廷機別墅人類片選擇。<END> 28\n",
      "<START>主義和不久，而在這一名管理能比很多時代。<END> 22\n",
      "<START>公司後仍監獄書至某種和捍國的主要同張副來所有助理和交易擔阻探屍癖結束，更善寫差異的動園。<END> 46\n",
      "<START>1706年1月完參加，雜夫人Grobires。<END> 25\n",
      "<START>仍然後來，目前還有以下情在劃碟持，常見拾益的作者夢製技翁繡的肉取代經濟體也有限公司的伊利穹近，倖存得到了2000°及其轉移居。<END> 65\n",
      "<START>三里時至蕉易的港島和叛明。<END> 15\n",
      "<START>但期年當26歲更之後，在每21日至1003年10年10月在太·巴黎沙安場開辦了俄米亞堡國家。<END> 48\n",
      "<START>2000年巴西納加上改為11艘波廿王。<END> 21\n",
      "<START>簽類和捍：素hielewisty，港島額在紐約22種，戰治以承斌後的代開必須紅光往上手，她下有的貨插圖正案失敗的爭場重慶。<END> 63\n",
      "<START>巴納斯（Ja結稱為，IGaur，河江蘇劇，俄夏薩爾徐州是李煥、崗、塔o蘭天地街治等8公45系復，僅189的震秀中斯基金融始之間的長田之後，在其文失去規模內容易一段，這種狐擊只有幾天，作化霸素的主編只有關擾。<END> 105\n",
      "<START>從1994年代表10月1日至18月4日起回了總r亂，香港館進入全找駐守的侵糕。<END> 41\n",
      "<START>為《神珠》的事會變成，例如生產生於熱場，直徑部打西部故帶，指「火光棍節」之前，SBS和ABA區的意識、精采節目前的過生上，韓幸籃發的寄身身分器致參與不是不能它的起智慧奏。<END> 87\n",
      "<START>「曲作第二十五歲勢」一起征，我們在共同年繼降，公眾正因的改兒和床潔內同居啟戒聞。<END> 42\n",
      "<START>由於他們感解在繁苗。<END> 12\n",
      "Avg sentence length: 42.35\n"
     ]
    }
   ],
   "source": [
    "generate_n_sentences(consider_prev=184, print_sentences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd3b3c",
   "metadata": {},
   "source": [
    "#### Part 1 Report:\n",
    "\n",
    "I referred to https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/ and defined a next-word-prediction model. In this case, it predicts the next Chinese character based on the previous characters, instead the 'next word' like in English, since a Chinese word can consisting one or multiple characters.\n",
    "\n",
    "I tried generating sentences by considers different number of previous characters. When only looking back at a few (1~10) characters. The sentences are extremely long and don't make sense, just random combinations of characters.\n",
    "\n",
    "When considering more and evetually all previous characters, the sentence lengths started to approximate the average length of read sentences in the training set. The overall generated sentences still don't make sense, but they don't look like gibberish anymore. Rather, they look like random 'Chinese words' combined in a somehow grammatical way, at least I can understand some of the words. (Cf from gibberish `Helar touf ghaid moft` to random but intellibible `Because they feel comprehend at foster seedling`).\n",
    "\n",
    "Moreover, the punctuation is correctly predicted, like the full stop `。` always appearing between the end of a sentence and \"\\<END>\"; the quotation marks `「 ... 」` always apearing together; and four-digit numbers always followed by `年 (year)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59495270",
   "metadata": {},
   "source": [
    "### Part 2 - Dual objectives (10 points)\n",
    "Copy the notebook from part 1 and augment the copy by adding back the word segmentation objective, as a second objective with its own loss.  (You could also in theory do Part 1 and Part 2 in reverse, by adding sentence generation with dual objectives first and then stripping out the word segmentation objective; this is equivalent.)  Note that multiple losses can be combined by simple, possibly weighted addition -- backpropagation works entirely correctly on the combined loss.\n",
    "\n",
    "Report and discuss the changes you made to the notebook using Markdown inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fe34a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(vocabsize)(x, h_state) => out1:[B,maxlen,2] ; out2:([B,maxlen-1,vocabsize], h_state)\n",
    "class DualModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size=200, lstm_size=150):\n",
    "        super(DualModel, self).__init__()\n",
    "        self.num_layers = 1\n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        # Two model classes\n",
    "        self.modelA = Segmenter(vocab_size, emb_size)\n",
    "        self.modelB = SentenceGenerator(vocab_size, emb_size, lstm_size)\n",
    "    \n",
    "    def forward(self, x, x_len, hidden_state):\n",
    "        # original x: B,185\n",
    "        \n",
    "        # modelA(x, lengths) => output = segmentation predictions\n",
    "        output1 = self.modelA(x, x_len)\n",
    "        \n",
    "        # modelB(x[:,:max(x_len)], hidden) => outputs = (logits, hidden)\n",
    "        output2 = self.modelB(x[:,:max(x_len)], hidden_state)\n",
    "        \n",
    "        return output1, output2\n",
    "        \n",
    "    #====================================================\n",
    "        \n",
    "    # Func to initilize a random hidden state  \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.num_layers, batch_size, self.lstm_size).zero_(),\n",
    "                weight.new(self.num_layers, batch_size, self.lstm_size).zero_())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c74b59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dualmodel(train_xy, model, epochs, device, model_fn, batch_size=50):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    batching = DataLoader(train_xy, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    cross_entropy_fn = nn.CrossEntropyLoss(ignore_index=0) # ignore sentence padding\n",
    "    nll_fn = nn.NLLLoss(ignore_index=-1) # ignore y padding\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        hidden = model.init_hidden(batch_size) # the initial random hidden state\n",
    "        \n",
    "        for i, (x, x_len, y) in enumerate(batching):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            hidden = tuple([s.data for s in hidden])\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # two outputs \n",
    "            out1, out2 = model(x, x_len, hidden)\n",
    "            \n",
    "            # output1 loss\n",
    "            expect1 = y[:, :max(x_len)] # B, max_x_len\n",
    "            loss1 = nll_fn(out1.transpose(1, 2), expect1)\n",
    "            \n",
    "            # output2 loss\n",
    "            pred, hidden = out2\n",
    "            expect2 = x[:, 1:max(x_len)+1] # next words\n",
    "            loss2 = cross_entropy_fn(pred.transpose(1, 2), expect2)\n",
    "            \n",
    "\n",
    "            loss = loss1+loss2\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            print(f\"epoch {e+1} avg loss: {total_loss/(i+1)}\", end='\\r')\n",
    "\n",
    "        print()\n",
    "        torch.save(model, model_fn)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8f9b21cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg loss: 7.3955021977424625\n",
      "epoch 2 avg loss: 6.4418727397918705\n",
      "epoch 3 avg loss: 6.1049072623252875\n",
      "epoch 4 avg loss: 5.8512919008731845\n",
      "epoch 5 avg loss: 5.6356389343738565\n",
      "epoch 6 avg loss: 5.4591644585132645\n",
      "epoch 7 avg loss: 5.3061556279659275\n",
      "epoch 8 avg loss: 5.1688736200332645\n",
      "epoch 9 avg loss: 5.0500814855098735\n",
      "epoch 10 avg loss: 4.9408833086490635\n",
      "epoch 11 avg loss: 4.8424501240253455\n",
      "epoch 12 avg loss: 4.7502390861511235\n",
      "epoch 13 avg loss: 4.6609840273857115\n",
      "epoch 14 avg loss: 4.5792471945285795\n",
      "epoch 15 avg loss: 4.5017314136028295\n",
      "epoch 16 avg loss: 4.4304992198944095\n",
      "epoch 17 avg loss: 4.3607246458530425\n",
      "epoch 18 avg loss: 4.2926826000213625\n",
      "epoch 19 avg loss: 4.2292533457279215\n",
      "epoch 20 avg loss: 4.1671144723892215\n",
      "epoch 21 avg loss: 4.1097656488418585\n",
      "epoch 22 avg loss: 4.0537209182977686\n",
      "epoch 23 avg loss: 3.9977472305297855\n",
      "epoch 24 avg loss: 3.9429872274398803\n",
      "epoch 25 avg loss: 3.8891284197568897\n",
      "epoch 26 avg loss: 3.8378148049116136\n",
      "epoch 27 avg loss: 3.7907382309436822\n",
      "epoch 28 avg loss: 3.7428816109895706\n",
      "epoch 29 avg loss: 3.7022347480058678\n",
      "epoch 30 avg loss: 3.6634141534566877\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(ids_dict)\n",
    "dualmodel_init = DualModel(vocab_size=vocab_size)\n",
    "gpu = 'cuda:3'\n",
    "\n",
    "dualmodel = train_dualmodel(train_xy, model=dualmodel_init, epochs=30, device=gpu, model_fn='dualmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55089f",
   "metadata": {},
   "source": [
    "#### Part 2 Report\n",
    "\n",
    "Originally I tried to combine both models so they can share the embedding function, but the models have different number of inputs (the SentenceGenerator needs hidden state as input) and internal packing/unpacking, which made the code long and complicated.\n",
    "\n",
    "In the end I simply call the previous two models as sub-models in the DualModel and calculate their respective output losses with two loss functions (cross entropy vs NLL). The loss of the DualModel is simply the sum of two losses. The pros is that the inputs are the same, the cons is that the x-input needs to be embedded twice since there are two sub-models, but since the inputs and the models are rather light-weight, it did not affect the computing efficiency too much. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0549f45",
   "metadata": {},
   "source": [
    "### Part 3 - Analysis (5 points)\n",
    "You now have three models.  The original word segmentation model, a sentence generation model, and a dual sentence-generation/word segmentation model. \n",
    "\n",
    "Compare the performance on the test data of the original word segmentation model between the original objective and the dual objective model.  In how many iterations do the models converge?  What are their final F1 and accuracy scores once they've converged? Are they any different?  If so, why?\n",
    "\n",
    "Make the same comparison between the sentence generation model and the dual-objective model, except the performance measure is the per-word perplexity on the text corpus.\n",
    "\n",
    "Report your findings in one of the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fa85fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualModel(\n",
       "  (modelA): Segmenter(\n",
       "    (emb): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (sig1): Sigmoid()\n",
       "    (lin): Linear(in_features=150, out_features=2, bias=True)\n",
       "    (softmax): LogSoftmax(dim=2)\n",
       "  )\n",
       "  (modelB): SentenceGenerator(\n",
       "    (embedding): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (fc): Linear(in_features=150, out_features=3650, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dualmodel = torch.load('dualmodel').to('cpu')\n",
    "dualmodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efa666",
   "metadata": {},
   "source": [
    "#### Comparing Segmenter and the DualModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4df0382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Segmenter vs DualModel (output1 only) & compare accuracy/f1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_accu_and_f1(collect_preds, collect_golds):\n",
    "    allpreds, allgolds = torch.cat(collect_preds).float(), torch.cat(collect_golds).float()\n",
    "\n",
    "    tp = sum(allgolds * allpreds)\n",
    "    fp = sum(allgolds * (~allpreds.bool()).float())\n",
    "    tn = sum((~allgolds.bool()).float() * (~allpreds.bool()).float())\n",
    "    fn = sum((~allgolds.bool()).float() * allpreds)\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    f1 = (2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    return accuracy, f1\n",
    "\n",
    "def train_and_eval(vocab_size, epochs, trainXY, testXY, device, batch_size=50, lr=0.001):\n",
    "    \n",
    "    # Train/test batches\n",
    "    train_batches = DataLoader(train_xy, batch_size=batch_size, shuffle=True)\n",
    "    test_batches = DataLoader(test_xy, batch_size=batch_size)\n",
    "    \n",
    "    # Models\n",
    "    modelA = Segmenter(vocab_size, 200).to(device)\n",
    "    modelB = DualModel(vocab_size).to(device)\n",
    "    \n",
    "    # Loss funcs & optimizers\n",
    "    cross_entropy_fn = nn.CrossEntropyLoss(ignore_index=0) # ignore sentence padding\n",
    "    nll_fn = nn.NLLLoss(ignore_index=-1) # ignore y padding\n",
    "    optimizerA, optimizerB = optim.Adam(modelA.parameters(), lr=lr), optim.Adam(modelB.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    # Each epoch: train models -> eval models, get accuracy and f1\n",
    "    all_accuA, all_accuB, all_f1A, all_f1B = [],[],[],[]\n",
    "    for e in range(epochs):\n",
    "        hidden = modelB.init_hidden(batch_size) # the initial random hidden state\n",
    "        \n",
    "        # TRAIN\n",
    "        modelA.train(); modelB.train()\n",
    "        for i, (x, x_len, y) in enumerate(train_batches):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # ====Train A==========================================\n",
    "            optimizerA.zero_grad()\n",
    "            \n",
    "            out = modelA(x, x_len) \n",
    "            expect = y[:, :max(x_len)] \n",
    "            \n",
    "            lossA = nll_fn(out.permute(0,2,1), expect) \n",
    "            lossA.backward(); optimizerA.step()\n",
    "            \n",
    "            \n",
    "            # ====Train B==========================================\n",
    "            optimizerB.zero_grad()\n",
    "            \n",
    "            hidden = tuple([s.data for s in hidden])\n",
    "            out1, out2 = modelB(x, x_len, hidden)\n",
    "            \n",
    "            # output1 loss\n",
    "            expect1 = y[:, :max(x_len)] \n",
    "            loss1 = nll_fn(out1.transpose(1, 2), expect1)\n",
    "            # output2 loss\n",
    "            pred, hidden = out2\n",
    "            expect2 = x[:, 1:max(x_len)+1] # next words\n",
    "            loss2 = cross_entropy_fn(pred.transpose(1, 2), expect2)\n",
    "\n",
    "            lossB = loss1+loss2\n",
    "            lossB.backward()\n",
    "            nn.utils.clip_grad_norm_(modelB.parameters(), 1)\n",
    "            optimizerB.step()\n",
    "            \n",
    "        \n",
    "        # EVAL & TEST\n",
    "        modelA.eval(); modelB.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            collect_modelA_preds = []\n",
    "            collect_modelB_preds = []\n",
    "            collect_golds = []\n",
    "            \n",
    "            hidden = modelB.init_hidden(batch_size) # the initial random hidden state\n",
    "            \n",
    "            for i, (x, x_len, y) in enumerate(test_batches):\n",
    "                x, y = x.to(device), y.to(device) # input-sentence, gold-labels\n",
    "                \n",
    "                # ModelA predictions \n",
    "                raw_predsA = modelA(x, x_len)\n",
    "                binary_predsA = raw_predsA.argmax(2)\n",
    "                \n",
    "                # ModelB predictions \n",
    "                hidden = modelB.init_hidden(batch_size)\n",
    "                raw_predsB, _ = modelB(x, x_len, hidden) # only need the first output\n",
    "                binary_predsB = raw_predsB.argmax(2)\n",
    "                \n",
    "                #================================\n",
    "                #Slice off the paddings of predictions/golds\n",
    "                current_batch_size = x.shape[0]\n",
    "                for i in range(current_batch_size):\n",
    "                    collect_modelA_preds.append(binary_predsA[i][:x_len[i]]) \n",
    "                    collect_modelB_preds.append(binary_predsB[i][:x_len[i]]) \n",
    "                    collect_golds.append(y[i][:x_len[i]])\n",
    "        \n",
    "        # Compare predictions of models with golds\n",
    "        accuracy_A, f1_A = get_accu_and_f1(collect_modelA_preds, collect_golds)\n",
    "        accuracy_B, f1_B = get_accu_and_f1(collect_modelB_preds, collect_golds)\n",
    "        \n",
    "        # Result of current epoch\n",
    "        all_accuA.append(accuracy_A)\n",
    "        all_accuB.append(accuracy_B)\n",
    "        all_f1A.append(f1_A)\n",
    "        all_f1B.append(f1_B)\n",
    "        print(f\"Training and evaluating Epoch {e+1}\", end='\\r')\n",
    "        \n",
    "\n",
    "    # Draw the line chart\n",
    "    the_epochs = list(range(1,epochs+1))    \n",
    "\n",
    "    # Four lines\n",
    "    plt.plot(the_epochs, all_accuA, label='Segmenter accuracy')\n",
    "    plt.plot(the_epochs, all_accuB, label='DualModel accuracy')\n",
    "    plt.plot(the_epochs, all_f1A, label='Segmenter f1')\n",
    "    plt.plot(the_epochs, all_f1B, label='DualModel f1')\n",
    "    \n",
    "    plt.title('Accuracy/F1 over iterations')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy & f1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "29050c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Epoch 30\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = len(ids_dict)\n",
    "\n",
    "train_and_eval(vocab_size,\n",
    "               epochs=30, \n",
    "               trainXY=train_xy, testXY=test_xy, device='cuda:1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d9ac8",
   "metadata": {},
   "source": [
    "#### Part 3.1 Report:\n",
    "\n",
    "The accuracies of the two models converge in around the 4th and 5th epoch and start to stabilise.\n",
    "\n",
    "The f1s also converge in the same epochs.\n",
    "\n",
    "Observing from the line chart, the accuracy/f1 of Segmenter fluctuated between epoch 5~20 while the DualModel was more stable. But the accuracy/f1 started to increase when approaching epoch 30, while Segmenter was stable at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a2ee0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(model, xy_data, device, model_outputs, batch_size=50):\n",
    "\n",
    "    batches = DataLoader(xy_data, batch_size=batch_size)\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    total_losses = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i,(x, x_len, _) in enumerate(batches):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        \n",
    "        # for single output model\n",
    "        if model_outputs == 1: \n",
    "            output, hidden = model(x[:,:max(x_len)], hidden) # B,max_x_len => B,max_x_len,V\n",
    "        # for dual output model\n",
    "        elif model_outputs == 2:\n",
    "            _, (output, hidden) = model(x, x_len, hidden)\n",
    "        else:\n",
    "            return 'model should have either 1 or 2 output(s)'\n",
    "        \n",
    "        \n",
    "        expect = x[:, 1:max(x_len)+1] # next words\n",
    "        loss = loss_fn(output.transpose(1, 2), expect)\n",
    "\n",
    "        \n",
    "        total_losses = torch.cat( (total_losses, loss.reshape(1)) )\n",
    "        mean_total_loss = torch.mean(total_losses)\n",
    "        perplexity  = torch.exp(mean_total_loss)\n",
    "\n",
    "        print(f'Perplexity based on mean loss: {perplexity}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ccd3ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity based on mean loss: 2505.24755859375\r",
      "Perplexity based on mean loss: 15517.4296875\r",
      "Perplexity based on mean loss: 63131.17578125\r",
      "Perplexity based on mean loss: 112570.4296875\r",
      "Perplexity based on mean loss: 233423.578125\r",
      "Perplexity based on mean loss: 409610.1875\r",
      "Perplexity based on mean loss: 523967.875\r",
      "Perplexity based on mean loss: 817497.5625\r",
      "Perplexity based on mean loss: 811924.3125\r",
      "Perplexity based on mean loss: 975354.125\r"
     ]
    }
   ],
   "source": [
    "get_perplexity(model_B, test_xy, device='cuda:3', model_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "8889d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity based on mean loss: 3619.995849609375\r",
      "Perplexity based on mean loss: 21835.283203125\r",
      "Perplexity based on mean loss: 91599.609375\r",
      "Perplexity based on mean loss: 164053.828125\r",
      "Perplexity based on mean loss: 353866.90625\r",
      "Perplexity based on mean loss: 636215.5625\r",
      "Perplexity based on mean loss: 811439.75\r",
      "Perplexity based on mean loss: 1282223.25\r",
      "Perplexity based on mean loss: 1264072.875\r",
      "Perplexity based on mean loss: 1533167.625\r"
     ]
    }
   ],
   "source": [
    "get_perplexity(dualmodel, test_xy, device='cuda:3', model_outputs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472b861",
   "metadata": {},
   "source": [
    "#### Part 3.2 Report:\n",
    "I didn't really understand how to compute the per-word perplexity, and instead found the information on https://stackoverflow.com/questions/59209086/calculate-perplexity-in-pytorch about how to get the perplexity from the cross entropy loss. The loss is computed by iterating the test data over 1 epoch. The perplexity is from the exponential of the mean total loss, as the sum of total loss is too large (calculating it would resulting in an infinite number).\n",
    "\n",
    "The results showed that the SentenceGenerator model has a much lower perplexity than that of the DualModel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
